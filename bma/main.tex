%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Large Colored Title Article
% LaTeX Template
% Version 1.0 (15/8/12)
%
% This template has been downloaded from:
% http://www.LaTeXTemplates.com
%
% Original author:
% Frits Wenneker (http://www.howtotex.com)
%
% License:
% CC BY-NC-SA 3.0 (http://creativecommons.org/licenses/by-nc-sa/3.0/)
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\input{layouts/large_report}

%----------------------------------------------------------------------------------------
% DOCUMENT
%----------------------------------------------------------------------------------------
\begin{document}

\input{parts/commands}
\begin{titlepage}
  \thispagestyle{empty}

  \title{
    BM Paper\bigskip\\
    \fontsize{20}{20}
    \selectfont
    AI applied to a simple 2D environment
  }
  \author{
    Principle Topic: change\bigskip\\
    Michael Gerber, Nicolas Ganz\\
    Under the supervision of Dr. Floeder
  }
  \date{Date of submission: 20.11.2012}

  \maketitle % Print the title
\end{titlepage}

\tableofcontents
%----------------------------------------------------------------------------------------
%	ABSTRACT
%----------------------------------------------------------------------------------------

\chapter{Abstract}
% The first character should be within \initial{}
\initial{T}\textbf{he creation of smart machines has become more important and more feasible than ever. AIs already influence many aspects of everyday life and are predicted to do much more in the future. In this paper we are looking at the field of artificial intelligence and are giving an example on how one could be implemented to solve problems in the simplified world of a 2D Jump and Run game. The question we are asking is: What methods are there to compose an AI, how do they differ and which suits our problem best?}

We wrote a simple Jump and Run game and gave it a clean API through which an AI could control it without knowing about the inner workings of the code. We researched AI algorithms, classified the problem given and wrote an AI to play the game.

In conclusion we learned that a fully observable, deterministic, benign and discrete environment like our game is best solved by learning the parameters through trial and error and applying them to a fixed algorithm that deals hierarchically with the steps required to win the game.

\chapter{Introduction}

This paper is about artificial intelligence and it's applications to solve problems in a two dimensional world with simplified laws of physics. We are educating ourselves on the topic of physics engines, game development and artificial intelligence. What we're trying to figure out is how those technologies work and especially how artificial intelligence is able to learn about an environment. The learning part is where the principle topic of change comes in: We want to know how the process of learning works. How does a mind acquiring knowledge and thereby change itself?

We expect there to be a variety of algorithms, knowledge structures and methods of gathering information, each one suitable for different types of problems.

The reason we chose this topic has to do with our job as programmers. Seeing what todays applications are capable of in terms of processing power and data storage one can't help but wonder what would be possible if we made those programs smarter in terms of decision making and understanding patterns. This inevitably leads to the question of how these types of thoughts compare to those of humans. The scientific field that is asking those question is artificial intelligence and we wanted to take this paper as an opportunity to learn more about the fascinating research it performs.

The paper first gives a general overview of what we learned about artificial intelligence and shows some real world applications. Then it gives a detailed description of our project and our research on physics engines.

%------------------------------------------------
\chapter{Artificial Intelligence}
\section{What is AI?}

This question has about as many answers as there are people studying artificial intelligence. Without getting too philosophical one could say that intelligence is defined by the efficiency of patterns used to solve problems in a complex environment and the ability to learn or generate new patterns by observing or testing.

Man-made programs to solve such problems have been around for decades and as algorithm efficiency and computational power increases they get ever more powerful.

An AI usually is directed towards one goal. This could mean solving a mathematical challenge most efficiently, finding patterns in huge amounts of data to categorize new sets of data or even to find smarter ways of learning.


\section{History of the Field}

The idea of artificial creatures acting and thinking like humans has been documented as far back as ancient Egypt. But it wasn't until the year 1955 that John McCarthy used the term artificial intelligence and defined it as "the science and engineering of making intelligent machines".
Only a year later AI research became a scientific field at the campus of Dartmouth College. During the 1960s the Department of Defense was heavily funding AI research and the field was taught around the world.
For the next decades research continued with big advances in problem solving but few real world applications. In 1997 the field drew a lot of public attention after IBM's chess computer Deep Blue famously defeated the reigning world champion Garry Kasparov.
In the 21st century AI has found many applications in fields like medical diagnostics, data mining or household appliances like the "Roomba". 

\section{Technological Singularity}

It is estimated that, about a hundred years from now, artificial intelligence will exceed that of humans. Following this event the machine will continue to build smarter versions of itself, leading to a rapid increase in AIs cognitive abilities. Since no human can predict the events after this point it is seen as the intellectual event horizon.

\newpage
\section{Real World Applications}

\subsection{Amazon Recommendations}
Everyone knows the ``People who bought X also bought Y''-kind of recommendations online shops provide you with. Sometimes they are spot on and other times they are as far off as they can be. The idea of course is to find patterns in customer interest which can be used to offer people things they are likely to buy thereby increasing profit.

So how do they work? It is all about finding similarities in data. In the case of products you have attributes like cost, size, style, manufacturer, etc. that let classify the product. Yet taken for themselves they are close to useless because two products that are similar in size and cost might not have anything in common at all. It's even worse. Imagine two lamps that have almost the same price, the same size and the same style. What's the probability that someone who bought the one lamp would also want to buy the other? Close to zero. Now why is that? For one thing it's unlikely that someone needs two lamps. It's even less likely that they would need two almost identical lamps. So apart from flat stats about a product one needs to take into account the nature of the product to make good recommendations. An example of such would be matching light bulbs for the lamp. 
This tells us two things. First we need to categorize a product. Not only in it's use (e.g. lamp, chair, table, clock) but also in what frequency demand for it arises. So for example one would like to buy a new shirt every month whereas a new computer is only required every few years. The second thing is that there are certain items which depend on other items to function. A coffee machine needs filters, a toy car needs batteries and a lamp needs light bulbs. Hence to make a smart suggestion one would link those items one way so that buying a laptop would yield to recommendation of a mouse but buying cat food would not recommend acquiring a new feline companion.

This probably all sounds perfectly reasonable. Every halfway decent online shop should be capable handling categories and dependencies between products. Since the assignment of such seems more or less obvious even to an intern why not just hire some of those to do it? It doesn't require an expensive AI to figure out that it would be a good idea to recommend "Harry Potter" part two to someone who bought part one. Yet if those where to only clues to go on the list of suggestions would be pretty short for most products. To make matters worse: Since those types of relations are so obvious, it's likely the customer thought of them already so they don't yield as much additional sales as "smart" recommendations would. This is where the AI algorithms come in.

Imagine what a resale company could do if they understood their customer's taste. If they knew what style of clothing she likes, whether she lives near a beach and thus is more likely to buy a new bathing suit in spring or when her mothers birthday was so they could recommend gifts for older women at that time of year. Admittedly these examples might are little extreme yet the efforts of the so called data miners definitely go in that direction. These three examples have been picked for a reason because they each depend on different types of data.

The style for example can be derived from the clothes the customer has bought in the past. From those the retailer could categorize his customers into groups that appear to like the same products and recommend things person A from this group bought to person B. Of course there is more to it than that. For example one needs to filter out noise which may be a piece of clothing a customer bought for someone else and thus does not match the pattern. Now an especially smart AI could even make a connection between such purchases and the friend or family member they where meant to. This data then could be used for a variety of further predictions about the customers buying behavior.

The fact whether someone lives near a beach (or swimming pool for that matter) can be easily determined by matching the IP address from which requests to the store website were made to the corresponding location. There is a lot more of this type of information that one can easily read from the web request like browser type, mobile phone model, referring website and by matters of recurring visits from different locations even estimates about the customer's place of work or their boyfriend's address. Now this type of information is only as useful as one is able to make sense of it. This is the true strength of an AI because it can find patterns in data that no one has been looking for so far.

\subsection{Web Search Algorithms}

In web search it is even more important than with large selections of products to have an automated way to make precise estimations about the value of something to someone. Furthermore the search provider not only wants to establish a prediction about how likely a person is to be looking for a certain web page but also about how likely he or she is to be looking for it right now. A lot of things factor into this like previously visited websites, behavior in choosing links and probably over a thousand other data points that might have been collected about a person. Yet even if there is no previous information about a search engine user available they can still make predictions based on the location, language and outside factors. An example of this might be the following scenario:

A user sits down in a Boston coffee shop using a browser, the signature of which has been modified to prevent it from being tracked back to that certain individual, to access her search provider of choice. She types in the word "dolphins". Now the first assumptions is that she is looking for the marine mammals. Yet the night before the football team by the same name might have played which would vastly improve the relevance of last nights game results. This increase of relevance can be justified by the fact that the user has set her language preference to American English which makes it far more likely that she is interested in the score than someone with a preference for French would be. But this isn't everything that is relevant to the search. Assuming that a band called "The Dolphins" is playing this week in Boston would make the band's website and a ticket sales site a lot more relevant to this search then it would be for someone from San Francisco.

Again this example shows how a shift in relevance might be obvious if pointed out but is extremely hard to predict for a human. Artificial intelligence can look at changes in user behavior (like increased requests to "The Dolphins" band website from Boston) and smartly adjust the ranking of certain websites. Of course this is an oversimplification of the problem but it shows nicely the basic idea of using AI to find patterns in changing data.

\subsection{DARPA Challenges}

The Defense Advanced Research Projects Agency has funded prize competitions that reward advances in research fields relevant to the Department of Defense. The initial challenge was to build autonomous ground vehicles or "self-driving cars". It was called the DARPA Grand Challenge and was first held in 2004. The goal was to build an autonomous vehicle that could drive the 240 km route through the desert fastest. None of the robot vehicles that entered the contest was able to complete the challenge. The one that performed best only finished five percent of the route before getting hung up on a rock. Therefore the event was repeated in 2005.

The second time around five vehicles were able to finish the race. With the team from Stanford University finishing first. 

In 2007 the DARPA Urban Challenge has been held requiring the vehicles to finish a 96 km course in an urban area while obeying traffic regulations and interacting with human drivers.

Currently Google is developing a driverless car which has already driven 300'000 miles without an accident. The project is led by Sebastian Thrun who also was the head of the Stanford team that won the 2005 DARPA Grand Challenge.

\newpage
\section{Classification of AI problems}

There are four major attributes to an AI problem. Each of them has severe impact on how one approaches to solve that given problem.
\begin{description}
\item Firstly there is the question of observability. Some environments are {\bf fully observable} while others are only {\bf partially observable}.
\item Secondly there is the factor of randomness. An environment can be completely {\bf deterministic} which means that taking an action always result in the expected state or {\bf stochastic}. In the latter case there is chance involved in determining the outcome of an action. A good example for this would be a game that requires one to roll dice.
\item Thirdly a problem might either be {\bf discrete} or {\bf continuous}. The former one meaning that there is a finite number of things to do and things to observe and the latter meaning that there is a factor to the problem that is infinite and has to be handled accordingly.
\item Fourthly the problems environment can be {\bf benign} or {\bf adversarial} which would mean that there are factors to it that are actively contradicting the AI's objective by taking actions that prevent it from achieving its goals. Most games are of adversarial nature because in order to succeed each player needs to take actions that make it harder for his opponents to win.
\end{description}

\newpage
\section{Important AI Algorithms in Detail}
\subsection{Tree Search}

In artificial intelligence many problems can be represented as trees. The first node of that tree is the initial state of the problem. From that state different actions can be taken which lead to new states. A good example of this is the game of Tic Tac Toe.

\begin{figure}[H]
  \includegraphics[width=0.45\textwidth]{images/tree_search_tic_tac_toe.png}
  \caption[\url{http://en.wikipedia.org/wiki/Tic-tac-toe}]{Tree representation of Tic Tac Toe turns from Wikipedia}
\end{figure}

There are different approaches for searching through trees each with their respective advantages and problems. Without additional knowledge about the situation the choice is between breadth-first search and depth-first search. The former one expanding always on the least explored path (broad) whereas the latter always expands the best explored (deepest) path. 

At the example of Tic Tac Toe this would mean that breadth-first search would look at all the nine first turn moves, evaluating whether they result in a winning state (which of course none of them do). Next it would look at the eight resulting states the opponent's turn could have put the game in for all of those nine states. This this result in another seventy-two nodes being expanded without any of them possibly being a winning state. The first winning state could occur in turn five which means that 26'132'625 states need to be calculated and evaluated. Yet since wins in the fifth turn are only possible if the opponent is playing badly on purpose it is far more likely that the tree has to be calculated to the 7th or even ninth turn.

Now depth-first search on the other hand would just pick one first turn move and expand on one of the possibly resulting second turn moves. This process is repeated until a final state is reached, which means that there are no actions that can be taken to transition this state into another. Final states in Tic Tac Toe are wins, loses and ties. After depth-first search reached a final state it backs up to the furthest expanded node and takes another action from that state.

In a game neither of those search methods is preferable because due to the adversarial nature of the game one always has to expand every possible action the opponent could take from a state in order to determine whether that state is "good" or "bad". If there is additional information available (like rules to this game) the AI can be taught smarter tree search algorithms. For example one could teach it to see certain patterns in game states which indicate that a state is preferable or not. A depth-first search that chooses nodes to expand on an estimated value of the resulting state instead of doing so randomly is called the A* algorithm.

\subsection{Bayes' Networks}

Often the problem an AI faces is stochastic and randomness suddenly plays a big role in choosing smart actions. Using probability to make decisions is a rather simple process when all the numbers are available. It does not take artificial intelligence to figure out that an action with a 90 percent chance of success is to be preferred to one with just 40 percent. But if there are multiple events whose chance of occurring depend on each other and not all of them are observable it gets trickier.

As an example of such a problem we assume a machine that can tell us the whether there will be an earthquake today or not. But this machine is faulty and in one out of six cases it lies. Now we know from statistics 0.03 is the probability of an earthquake happening in this area. Now given that the machine tells us today is an earthquake day what is the chance of an actual earthquake happening?

To calculate this one uses {\bf Bayes' Rule} which states this. 

\[P(A|B)=\frac{P(B|A) * P(A)}{P(B)}\]

This reads as: The probability of event A occurring given that we observed event B has occurred is equal to the probability of event B occurring given that event A occurred multiplied by the probability of event A occurring and normalized by the probability of event B occurring.

If event B is not known but is only dependent on event A, the rule can also be written as:

\[P(A|B)=\frac{P(B|A) * P(A)}{P(B|A)*P(A)+P(B|!A)*P(!A)}\]

Using this rule one can construct complicated networks of event that depend on each other thus making probabilities available that were previously unknown or are changed by readings of sensors.

\subsection{Markov Decision Processes}

When dealing with stochastic environments one needs to change the approach on planning. While the path of actions to a goal in a fully observable, deterministic environment can be planned in advance and can then be executed without the need to make any adjustments along the way, this is not true for stochastic environments. Because of the random nature of an actions outcome one is forced to reevaluate his priorities. Taking an action that may lead directly to the goal but also holds a small chance of resulting in an undesirable state may suddenly be much less preferable than one that requires additional steps yet holds no risk.

To account for the stochasticity of the actions one computes a value function for states that looks like this.

\[V(s) \leftarrow \left [\begin{matrix} max \\ a \end{matrix} \gamma * \sum_{s'} P(s'|a,s)* V(s')  \right ]+R(s)\]

It reads as follows: The value of state {\bf s} is the maximum over the value of all actions {\bf a} (that can be taken from state {\bf s}). The value of action {\bf a} being defined by the sum over the probability of all possibly resulting states {\bf $s'$} given that one is in state {\bf s} and performs action {\bf a} multiplied by the value of this state {\bf $s'$}. The action value is also multiplied by the discount factor $\gamma$  which is set to a value smaller than one to make action sequences that take less steps than others get higher values. To this one also adds the value R of being in state {\bf s} which may also be negative to represent the cost of getting to that state.

Using this formula the AI can calculate the best sequence of actions from any state at any time. Instead of just calculating a sequence of actions at the beginning the AI recalculates this value if possible after every step taken to maximize the chance of success.

\chapter{Project}
\input{parts/project}

%----------------------------------------------------------------------------------------

\chapter{Conclusion}

For our project we planned and developed a simple game in HTML5 and JavaScript and learned in the process about physics engines and game development. When we were finished we asked ourselves what an AI would need to know to play the game and swiftly came to the conclusion that it was the same things any human player would need to know. Yet, the AI could not "see" the holes and the blocks in the game so we gave it an interface through which it could ask about their positions. Providing the AI with the interface allowed us to write code that, simply put, looked at the environment we gave it, performed an action and compared the resulting environment with it predecessor. With this method it was able to learn if actions were good or bad and how it could improve its efficiency.

The answer to our question is that yes, there are different classifications of AI problems and that in many ways the playing of a game is one of the easier ones. While problems much more compilcated than ours can be solves through AI technologies they require computational power that is far beyond that of a personal computer and the algorithmic complexity also grows exponentially with the number of factors and uncertainties in those problems. We are very satisfied with the solutions our AI found for the game problem and even more with what we have learned in the process of writing it. We believe to have a much deeper understanding of machine learning and learning in general.

This project marks a nice starting point for our work with AIs and we both are planning to use what we have learned in coming software projects. We are going to further our knowledge in this area because there is still a lot to learn.

In respect to the project itself, further work could include making it stochastic by adding random components like moving blocks or making it adversarial by adding limitedly intelligent opponents to it. These changes to the problem would not only require the adding of additional parameters in the existing code but probably a complete rewrite since the change in classification requires a completely different approach to the problem.

\onecolumn
\chapter{Sources}

\section{Sources}
\begin{description}
  \item[Physics Engines] \hfill \\
    \begin{itemize}
      \item \printhref{http://en.wikipedia.org/wiki/Physics\_engine}{Physics engine - Wikipedia}
    \end{itemize}
  \item[Game Engines] \hfill \\
    \begin{itemize}
      \item \printhref{http://en.wikipedia.org/wiki/Game\_engine}{Game engine - Wikipedia}
      \item \printhref{http://www.crytek.com/cryengine}{CryENGINE $|$ Crytek}
      \item \printhref{http://www.unrealengine.com}{Game Engine Technology by Unreal}
      \item \printhref{http://en.wikipedia.org/wiki/Anvil\_(game\_engine)}{Anvil (game engine) - Wikipedia}
      \item \printhref{http://en.wikipedia.org/wiki/IW\_engine)}{IW engine - Wikipedia}
    \end{itemize}
  \item[The Game] \hfill \\
    \begin{itemize}
      \item \printhref{http://craftyjs.com/}{Crafty - Javascript Game Engine}
    \end{itemize}
  \item[AI] \hfill \\
    \begin{itemize}
      \item \printhref{http://ai-class.org}{AI Class - A Stanford online class on artificial intelligence}
      \item {Artificial Intelligence: A Modern Approach - by Stuart Russell and Peter Norvig }
      \item {Gödel, Escher, Bach: an Eternal Golden Braid - by Douglas Hofstadter }
    \end{itemize}
\end{description}

\cleardoublepage
\phantomsection
\addcontentsline{toc}{section}{List of Figures}
\listoffigures

\end{document}
